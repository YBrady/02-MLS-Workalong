{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10 Machine Learning & Statistics Workalong\n",
    "\n",
    "## Classification of Iris\n",
    "\n",
    "### Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# For building neural networks.\n",
    "import keras as kr\n",
    "\n",
    "# For interacting with data sets.\n",
    "import pandas as pd\n",
    "\n",
    "# For encoding categorical variables.\n",
    "import sklearn.preprocessing as pre\n",
    "\n",
    "# For splitting into training and test sets.\n",
    "import sklearn.model_selection as mod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris data set from a URL.\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/ianmcloughlin/datasets/master/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width      class\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "5             5.4          3.9           1.7          0.4     setosa\n",
       "6             4.6          3.4           1.4          0.3     setosa\n",
       "7             5.0          3.4           1.5          0.2     setosa\n",
       "8             4.4          2.9           1.4          0.2     setosa\n",
       "9             4.9          3.1           1.5          0.1     setosa\n",
       "10            5.4          3.7           1.5          0.2     setosa\n",
       "11            4.8          3.4           1.6          0.2     setosa\n",
       "12            4.8          3.0           1.4          0.1     setosa\n",
       "13            4.3          3.0           1.1          0.1     setosa\n",
       "14            5.8          4.0           1.2          0.2     setosa\n",
       "15            5.7          4.4           1.5          0.4     setosa\n",
       "16            5.4          3.9           1.3          0.4     setosa\n",
       "17            5.1          3.5           1.4          0.3     setosa\n",
       "18            5.7          3.8           1.7          0.3     setosa\n",
       "19            5.1          3.8           1.5          0.3     setosa\n",
       "20            5.4          3.4           1.7          0.2     setosa\n",
       "21            5.1          3.7           1.5          0.4     setosa\n",
       "22            4.6          3.6           1.0          0.2     setosa\n",
       "23            5.1          3.3           1.7          0.5     setosa\n",
       "24            4.8          3.4           1.9          0.2     setosa\n",
       "25            5.0          3.0           1.6          0.2     setosa\n",
       "26            5.0          3.4           1.6          0.4     setosa\n",
       "27            5.2          3.5           1.5          0.2     setosa\n",
       "28            5.2          3.4           1.4          0.2     setosa\n",
       "29            4.7          3.2           1.6          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "120           6.9          3.2           5.7          2.3  virginica\n",
       "121           5.6          2.8           4.9          2.0  virginica\n",
       "122           7.7          2.8           6.7          2.0  virginica\n",
       "123           6.3          2.7           4.9          1.8  virginica\n",
       "124           6.7          3.3           5.7          2.1  virginica\n",
       "125           7.2          3.2           6.0          1.8  virginica\n",
       "126           6.2          2.8           4.8          1.8  virginica\n",
       "127           6.1          3.0           4.9          1.8  virginica\n",
       "128           6.4          2.8           5.6          2.1  virginica\n",
       "129           7.2          3.0           5.8          1.6  virginica\n",
       "130           7.4          2.8           6.1          1.9  virginica\n",
       "131           7.9          3.8           6.4          2.0  virginica\n",
       "132           6.4          2.8           5.6          2.2  virginica\n",
       "133           6.3          2.8           5.1          1.5  virginica\n",
       "134           6.1          2.6           5.6          1.4  virginica\n",
       "135           7.7          3.0           6.1          2.3  virginica\n",
       "136           6.3          3.4           5.6          2.4  virginica\n",
       "137           6.4          3.1           5.5          1.8  virginica\n",
       "138           6.0          3.0           4.8          1.8  virginica\n",
       "139           6.9          3.1           5.4          2.1  virginica\n",
       "140           6.7          3.1           5.6          2.4  virginica\n",
       "141           6.9          3.1           5.1          2.3  virginica\n",
       "142           5.8          2.7           5.1          1.9  virginica\n",
       "143           6.8          3.2           5.9          2.3  virginica\n",
       "144           6.7          3.3           5.7          2.5  virginica\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the inputs from the rest of the variables.\n",
    "inputs = df[['petal_length', 'petal_width', 'sepal_length', 'sepal_width']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     petal_length  petal_width  sepal_length  sepal_width\n",
       "0             1.4          0.2           5.1          3.5\n",
       "1             1.4          0.2           4.9          3.0\n",
       "2             1.3          0.2           4.7          3.2\n",
       "3             1.5          0.2           4.6          3.1\n",
       "4             1.4          0.2           5.0          3.6\n",
       "5             1.7          0.4           5.4          3.9\n",
       "6             1.4          0.3           4.6          3.4\n",
       "7             1.5          0.2           5.0          3.4\n",
       "8             1.4          0.2           4.4          2.9\n",
       "9             1.5          0.1           4.9          3.1\n",
       "10            1.5          0.2           5.4          3.7\n",
       "11            1.6          0.2           4.8          3.4\n",
       "12            1.4          0.1           4.8          3.0\n",
       "13            1.1          0.1           4.3          3.0\n",
       "14            1.2          0.2           5.8          4.0\n",
       "15            1.5          0.4           5.7          4.4\n",
       "16            1.3          0.4           5.4          3.9\n",
       "17            1.4          0.3           5.1          3.5\n",
       "18            1.7          0.3           5.7          3.8\n",
       "19            1.5          0.3           5.1          3.8\n",
       "20            1.7          0.2           5.4          3.4\n",
       "21            1.5          0.4           5.1          3.7\n",
       "22            1.0          0.2           4.6          3.6\n",
       "23            1.7          0.5           5.1          3.3\n",
       "24            1.9          0.2           4.8          3.4\n",
       "25            1.6          0.2           5.0          3.0\n",
       "26            1.6          0.4           5.0          3.4\n",
       "27            1.5          0.2           5.2          3.5\n",
       "28            1.4          0.2           5.2          3.4\n",
       "29            1.6          0.2           4.7          3.2\n",
       "..            ...          ...           ...          ...\n",
       "120           5.7          2.3           6.9          3.2\n",
       "121           4.9          2.0           5.6          2.8\n",
       "122           6.7          2.0           7.7          2.8\n",
       "123           4.9          1.8           6.3          2.7\n",
       "124           5.7          2.1           6.7          3.3\n",
       "125           6.0          1.8           7.2          3.2\n",
       "126           4.8          1.8           6.2          2.8\n",
       "127           4.9          1.8           6.1          3.0\n",
       "128           5.6          2.1           6.4          2.8\n",
       "129           5.8          1.6           7.2          3.0\n",
       "130           6.1          1.9           7.4          2.8\n",
       "131           6.4          2.0           7.9          3.8\n",
       "132           5.6          2.2           6.4          2.8\n",
       "133           5.1          1.5           6.3          2.8\n",
       "134           5.6          1.4           6.1          2.6\n",
       "135           6.1          2.3           7.7          3.0\n",
       "136           5.6          2.4           6.3          3.4\n",
       "137           5.5          1.8           6.4          3.1\n",
       "138           4.8          1.8           6.0          3.0\n",
       "139           5.4          2.1           6.9          3.1\n",
       "140           5.6          2.4           6.7          3.1\n",
       "141           5.1          2.3           6.9          3.1\n",
       "142           5.1          1.9           5.8          2.7\n",
       "143           5.9          2.3           6.8          3.2\n",
       "144           5.7          2.5           6.7          3.3\n",
       "145           5.2          2.3           6.7          3.0\n",
       "146           5.0          1.9           6.3          2.5\n",
       "147           5.2          2.0           6.5          3.0\n",
       "148           5.4          2.3           6.2          3.4\n",
       "149           5.1          1.8           5.9          3.0\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoded outputs\n",
    "$$\n",
    "\\begin{align*}\n",
    "  setosa      \\rightarrow  [1,0,0] \\\\\n",
    "  versicolor  \\rightarrow  [0,1,0] \\\\\n",
    "  virginica   \\rightarrow  [0,0,1]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the classes as above.\n",
    "encoder = pre.LabelBinarizer() # LabelBinarizer like OneHotEncoder\n",
    "encoder.fit(df['class'])\n",
    "outputs = encoder.transform(df['class'])\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea\n",
    "The neural network will turn four floating point inputs into three \"floating point\" outputs.\n",
    "\n",
    "$$ [5.1, 3.5, 1.4, 0.2] \\rightarrow [0.8, 0.19, 0.01] $$\n",
    "$$ [5.1, 3.5, 1.4, 0.2] \\rightarrow [1, 0, 0] $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a neural network, building it by layers.\n",
    "model = kr.models.Sequential()\n",
    "\n",
    "# Add a hidden layer with x neurons and an input layer with 4.\n",
    "model.add(kr.layers.Dense(units=30, activation='relu', input_dim=4))\n",
    "# Add a three neuron output layer.\n",
    "model.add(kr.layers.Dense(units=3, activation='softmax'))\n",
    "\n",
    "# Build the graph.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the inputs and outputs into training and test sets.\n",
    "inputs_train, inputs_test, outputs_train, outputs_test = mod.train_test_split(inputs, outputs, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "petal_length    4.2\n",
       "petal_width     1.3\n",
       "sepal_length    5.6\n",
       "sepal_width     2.7\n",
       "Name: 94, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ybrady\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.09315881, 0.81978244, 0.0870588 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stupid prediction as the model has not yet been trained\n",
    "model.predict(inputs_test.as_matrix()[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "120/120 [==============================] - 0s 864us/step - loss: 1.1059 - accuracy: 0.3333\n",
      "Epoch 2/15\n",
      "120/120 [==============================] - 0s 91us/step - loss: 0.8926 - accuracy: 0.5333\n",
      "Epoch 3/15\n",
      "120/120 [==============================] - 0s 66us/step - loss: 0.8121 - accuracy: 0.7250\n",
      "Epoch 4/15\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.7764 - accuracy: 0.7000\n",
      "Epoch 5/15\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.7373 - accuracy: 0.7000\n",
      "Epoch 6/15\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.6819 - accuracy: 0.7333\n",
      "Epoch 7/15\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.6708 - accuracy: 0.7000\n",
      "Epoch 8/15\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.6393 - accuracy: 0.7500\n",
      "Epoch 9/15\n",
      "120/120 [==============================] - 0s 66us/step - loss: 0.6059 - accuracy: 0.7417\n",
      "Epoch 10/15\n",
      "120/120 [==============================] - 0s 108us/step - loss: 0.5795 - accuracy: 0.7750\n",
      "Epoch 11/15\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.5721 - accuracy: 0.8167\n",
      "Epoch 12/15\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.5569 - accuracy: 0.8083\n",
      "Epoch 13/15\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.5310 - accuracy: 0.8333\n",
      "Epoch 14/15\n",
      "120/120 [==============================] - 0s 91us/step - loss: 0.5135 - accuracy: 0.8000\n",
      "Epoch 15/15\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.5101 - accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x26d3c1eceb8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the neural network.\n",
    "model.fit(inputs_train, outputs_train, epochs=15, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ybrady\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.08379745, 0.5316977 , 0.3845049 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(inputs_test.as_matrix()[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['versicolor', 'setosa', 'versicolor', 'virginica', 'setosa',\n",
       "       'virginica', 'setosa', 'setosa', 'virginica', 'versicolor',\n",
       "       'setosa', 'versicolor', 'virginica', 'virginica', 'versicolor',\n",
       "       'virginica', 'setosa', 'versicolor', 'versicolor', 'setosa',\n",
       "       'setosa', 'setosa', 'versicolor', 'virginica', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'setosa', 'setosa', 'setosa'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have the network predict the classes of the test inputs.\n",
    "predictions = model.predict(inputs_test)\n",
    "predictions_labels = encoder.inverse_transform(predictions) # Unencode\n",
    "predictions_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the predictions to the actual classes.\n",
    "predictions_labels == encoder.inverse_transform(outputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictions_labels == encoder.inverse_transform(outputs_test)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.decomposition as dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.187146</td>\n",
       "      <td>1.445908</td>\n",
       "      <td>-0.128590</td>\n",
       "      <td>-1.811704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.247343</td>\n",
       "      <td>1.054208</td>\n",
       "      <td>1.536132</td>\n",
       "      <td>-1.721308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.577086</td>\n",
       "      <td>0.405157</td>\n",
       "      <td>0.162445</td>\n",
       "      <td>0.977871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.498508</td>\n",
       "      <td>1.013567</td>\n",
       "      <td>0.199452</td>\n",
       "      <td>-0.068258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.419334</td>\n",
       "      <td>0.158521</td>\n",
       "      <td>0.865250</td>\n",
       "      <td>-0.314005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.360898</td>\n",
       "      <td>-0.270391</td>\n",
       "      <td>-0.350761</td>\n",
       "      <td>0.278249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.676656</td>\n",
       "      <td>-0.964249</td>\n",
       "      <td>-1.997965</td>\n",
       "      <td>-0.858986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.045082</td>\n",
       "      <td>1.563044</td>\n",
       "      <td>0.957627</td>\n",
       "      <td>-0.083311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.903693</td>\n",
       "      <td>-0.849588</td>\n",
       "      <td>0.443797</td>\n",
       "      <td>3.378778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.145723</td>\n",
       "      <td>-0.615288</td>\n",
       "      <td>1.814397</td>\n",
       "      <td>1.577036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.073357</td>\n",
       "      <td>1.514151</td>\n",
       "      <td>-0.898810</td>\n",
       "      <td>0.048895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.725125</td>\n",
       "      <td>-0.561192</td>\n",
       "      <td>-0.569664</td>\n",
       "      <td>0.503189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.073674</td>\n",
       "      <td>0.869408</td>\n",
       "      <td>-0.833831</td>\n",
       "      <td>0.128785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.560633</td>\n",
       "      <td>-0.869888</td>\n",
       "      <td>-0.825919</td>\n",
       "      <td>0.261408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.022194</td>\n",
       "      <td>-0.437583</td>\n",
       "      <td>0.139993</td>\n",
       "      <td>1.097972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.246292</td>\n",
       "      <td>-0.313738</td>\n",
       "      <td>0.304477</td>\n",
       "      <td>0.412822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.668195</td>\n",
       "      <td>0.319687</td>\n",
       "      <td>-0.554715</td>\n",
       "      <td>-1.254746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.212523</td>\n",
       "      <td>2.586595</td>\n",
       "      <td>1.878940</td>\n",
       "      <td>-0.750749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.215379</td>\n",
       "      <td>-0.432724</td>\n",
       "      <td>0.909849</td>\n",
       "      <td>1.189997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.356553</td>\n",
       "      <td>-0.405619</td>\n",
       "      <td>1.369651</td>\n",
       "      <td>-0.772040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.265146</td>\n",
       "      <td>0.276584</td>\n",
       "      <td>-0.936769</td>\n",
       "      <td>0.278411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.615043</td>\n",
       "      <td>-0.521536</td>\n",
       "      <td>-1.835404</td>\n",
       "      <td>0.305585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.359186</td>\n",
       "      <td>0.360878</td>\n",
       "      <td>0.113155</td>\n",
       "      <td>-0.196482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.385887</td>\n",
       "      <td>2.171804</td>\n",
       "      <td>-0.422956</td>\n",
       "      <td>0.281796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.596563</td>\n",
       "      <td>0.715384</td>\n",
       "      <td>-1.240454</td>\n",
       "      <td>0.030619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.281220</td>\n",
       "      <td>-1.286240</td>\n",
       "      <td>-0.083507</td>\n",
       "      <td>-0.244784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1.434931</td>\n",
       "      <td>1.990673</td>\n",
       "      <td>-1.289381</td>\n",
       "      <td>2.145667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.242866</td>\n",
       "      <td>-1.186858</td>\n",
       "      <td>-0.708896</td>\n",
       "      <td>-1.550470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.132280</td>\n",
       "      <td>-0.986399</td>\n",
       "      <td>-1.576092</td>\n",
       "      <td>-1.470789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1.452642</td>\n",
       "      <td>1.208499</td>\n",
       "      <td>0.012427</td>\n",
       "      <td>-0.175304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.027808</td>\n",
       "      <td>0.674477</td>\n",
       "      <td>-0.646806</td>\n",
       "      <td>0.235831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.041249</td>\n",
       "      <td>1.470804</td>\n",
       "      <td>-0.243572</td>\n",
       "      <td>0.183468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>-1.317167</td>\n",
       "      <td>-0.068383</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>-1.015464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.443382</td>\n",
       "      <td>0.275715</td>\n",
       "      <td>-0.235523</td>\n",
       "      <td>-1.116369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1.010507</td>\n",
       "      <td>-0.262322</td>\n",
       "      <td>2.612061</td>\n",
       "      <td>0.314653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.360438</td>\n",
       "      <td>0.802384</td>\n",
       "      <td>-2.182448</td>\n",
       "      <td>1.074203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-1.366809</td>\n",
       "      <td>0.342685</td>\n",
       "      <td>-0.784798</td>\n",
       "      <td>0.702584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-1.332738</td>\n",
       "      <td>-1.792010</td>\n",
       "      <td>0.769453</td>\n",
       "      <td>-1.815945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.094450</td>\n",
       "      <td>-0.357947</td>\n",
       "      <td>1.168842</td>\n",
       "      <td>1.831131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.423268</td>\n",
       "      <td>1.177181</td>\n",
       "      <td>-1.774222</td>\n",
       "      <td>1.740157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.680266</td>\n",
       "      <td>-1.077729</td>\n",
       "      <td>-1.179727</td>\n",
       "      <td>0.055663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.137013</td>\n",
       "      <td>0.149026</td>\n",
       "      <td>-0.818718</td>\n",
       "      <td>0.851276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.893513</td>\n",
       "      <td>-0.222360</td>\n",
       "      <td>1.714803</td>\n",
       "      <td>1.429779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>-1.320931</td>\n",
       "      <td>-1.331136</td>\n",
       "      <td>-0.960961</td>\n",
       "      <td>1.263184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>-1.506548</td>\n",
       "      <td>0.699343</td>\n",
       "      <td>0.623367</td>\n",
       "      <td>-0.496767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.144802</td>\n",
       "      <td>0.634515</td>\n",
       "      <td>0.250451</td>\n",
       "      <td>-0.879294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-1.164989</td>\n",
       "      <td>-0.241484</td>\n",
       "      <td>0.112323</td>\n",
       "      <td>1.019919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1.390900</td>\n",
       "      <td>-1.644047</td>\n",
       "      <td>1.540819</td>\n",
       "      <td>0.741212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1.097461</td>\n",
       "      <td>0.545988</td>\n",
       "      <td>-1.233283</td>\n",
       "      <td>-0.500230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.080966</td>\n",
       "      <td>0.581324</td>\n",
       "      <td>0.639313</td>\n",
       "      <td>-0.990677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.652229</td>\n",
       "      <td>1.261752</td>\n",
       "      <td>1.029339</td>\n",
       "      <td>-0.149777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>-1.408396</td>\n",
       "      <td>-0.619049</td>\n",
       "      <td>0.290241</td>\n",
       "      <td>-1.078657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1.075855</td>\n",
       "      <td>-0.691539</td>\n",
       "      <td>1.027568</td>\n",
       "      <td>-0.405822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>-1.305107</td>\n",
       "      <td>0.402953</td>\n",
       "      <td>-0.321138</td>\n",
       "      <td>-0.372700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.546043</td>\n",
       "      <td>1.331544</td>\n",
       "      <td>1.791811</td>\n",
       "      <td>0.337428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.419009</td>\n",
       "      <td>-0.677419</td>\n",
       "      <td>-0.058318</td>\n",
       "      <td>0.034469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.843745</td>\n",
       "      <td>0.486949</td>\n",
       "      <td>-0.131815</td>\n",
       "      <td>0.518193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.925806</td>\n",
       "      <td>0.408862</td>\n",
       "      <td>0.372028</td>\n",
       "      <td>-1.588361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1.626266</td>\n",
       "      <td>-1.155489</td>\n",
       "      <td>-1.200438</td>\n",
       "      <td>-0.688908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>-1.440571</td>\n",
       "      <td>-0.188918</td>\n",
       "      <td>-0.612584</td>\n",
       "      <td>1.135105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     petal_length  petal_width  sepal_length  sepal_width\n",
       "0        0.187146     1.445908     -0.128590    -1.811704\n",
       "1        0.247343     1.054208      1.536132    -1.721308\n",
       "2        0.577086     0.405157      0.162445     0.977871\n",
       "3       -1.498508     1.013567      0.199452    -0.068258\n",
       "4       -1.419334     0.158521      0.865250    -0.314005\n",
       "5       -1.360898    -0.270391     -0.350761     0.278249\n",
       "6        1.676656    -0.964249     -1.997965    -0.858986\n",
       "7       -0.045082     1.563044      0.957627    -0.083311\n",
       "8        0.903693    -0.849588      0.443797     3.378778\n",
       "9        1.145723    -0.615288      1.814397     1.577036\n",
       "10      -0.073357     1.514151     -0.898810     0.048895\n",
       "11       0.725125    -0.561192     -0.569664     0.503189\n",
       "12       0.073674     0.869408     -0.833831     0.128785\n",
       "13       0.560633    -0.869888     -0.825919     0.261408\n",
       "14       1.022194    -0.437583      0.139993     1.097972\n",
       "15      -1.246292    -0.313738      0.304477     0.412822\n",
       "16       0.668195     0.319687     -0.554715    -1.254746\n",
       "17       0.212523     2.586595      1.878940    -0.750749\n",
       "18      -1.215379    -0.432724      0.909849     1.189997\n",
       "19       0.356553    -0.405619      1.369651    -0.772040\n",
       "20      -1.265146     0.276584     -0.936769     0.278411\n",
       "21       0.615043    -0.521536     -1.835404     0.305585\n",
       "22       0.359186     0.360878      0.113155    -0.196482\n",
       "23      -0.385887     2.171804     -0.422956     0.281796\n",
       "24       0.596563     0.715384     -1.240454     0.030619\n",
       "25      -1.281220    -1.286240     -0.083507    -0.244784\n",
       "26      -1.434931     1.990673     -1.289381     2.145667\n",
       "27       1.242866    -1.186858     -0.708896    -1.550470\n",
       "28       1.132280    -0.986399     -1.576092    -1.470789\n",
       "29      -1.452642     1.208499      0.012427    -0.175304\n",
       "..            ...          ...           ...          ...\n",
       "90       0.027808     0.674477     -0.646806     0.235831\n",
       "91       0.041249     1.470804     -0.243572     0.183468\n",
       "92      -1.317167    -0.068383      0.314735    -1.015464\n",
       "93       0.443382     0.275715     -0.235523    -1.116369\n",
       "94       1.010507    -0.262322      2.612061     0.314653\n",
       "95       0.360438     0.802384     -2.182448     1.074203\n",
       "96      -1.366809     0.342685     -0.784798     0.702584\n",
       "97      -1.332738    -1.792010      0.769453    -1.815945\n",
       "98       1.094450    -0.357947      1.168842     1.831131\n",
       "99       0.423268     1.177181     -1.774222     1.740157\n",
       "100      0.680266    -1.077729     -1.179727     0.055663\n",
       "101      0.137013     0.149026     -0.818718     0.851276\n",
       "102      0.893513    -0.222360      1.714803     1.429779\n",
       "103     -1.320931    -1.331136     -0.960961     1.263184\n",
       "104     -1.506548     0.699343      0.623367    -0.496767\n",
       "105      0.144802     0.634515      0.250451    -0.879294\n",
       "106     -1.164989    -0.241484      0.112323     1.019919\n",
       "107      1.390900    -1.644047      1.540819     0.741212\n",
       "108      1.097461     0.545988     -1.233283    -0.500230\n",
       "109      0.080966     0.581324      0.639313    -0.990677\n",
       "110      0.652229     1.261752      1.029339    -0.149777\n",
       "111     -1.408396    -0.619049      0.290241    -1.078657\n",
       "112      1.075855    -0.691539      1.027568    -0.405822\n",
       "113     -1.305107     0.402953     -0.321138    -0.372700\n",
       "114      0.546043     1.331544      1.791811     0.337428\n",
       "115      0.419009    -0.677419     -0.058318     0.034469\n",
       "116      0.843745     0.486949     -0.131815     0.518193\n",
       "117      0.925806     0.408862      0.372028    -1.588361\n",
       "118      1.626266    -1.155489     -1.200438    -0.688908\n",
       "119     -1.440571    -0.188918     -0.612584     1.135105\n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-component Analysis\n",
    "pca = dec.PCA(n_components=4, whiten=True)\n",
    "pca.fit(inputs_train)\n",
    "# Whiten the dataset\n",
    "inputs_train_white = pd.DataFrame(pca.transform(inputs_train), columns=inputs_train.columns)\n",
    "inputs_train_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a neural network, building it by layers.\n",
    "model = kr.models.Sequential()\n",
    "\n",
    "# Add a hidden layer with x neurons and an input layer with 4.\n",
    "model.add(kr.layers.Dense(units=30, activation='relu', input_dim=4))\n",
    "# Add a three neuron output layer.\n",
    "model.add(kr.layers.Dense(units=3, activation='softmax'))\n",
    "\n",
    "# Build the graph.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "120/120 [==============================] - 0s 765us/step - loss: 1.4159 - accuracy: 0.1333\n",
      "Epoch 2/15\n",
      "120/120 [==============================] - 0s 75us/step - loss: 1.3270 - accuracy: 0.1333\n",
      "Epoch 3/15\n",
      "120/120 [==============================] - 0s 66us/step - loss: 1.2503 - accuracy: 0.1750\n",
      "Epoch 4/15\n",
      "120/120 [==============================] - 0s 75us/step - loss: 1.1810 - accuracy: 0.2500\n",
      "Epoch 5/15\n",
      "120/120 [==============================] - 0s 83us/step - loss: 1.1206 - accuracy: 0.3417\n",
      "Epoch 6/15\n",
      "120/120 [==============================] - 0s 83us/step - loss: 1.0653 - accuracy: 0.4417\n",
      "Epoch 7/15\n",
      "120/120 [==============================] - 0s 83us/step - loss: 1.0165 - accuracy: 0.5417\n",
      "Epoch 8/15\n",
      "120/120 [==============================] - 0s 91us/step - loss: 0.9705 - accuracy: 0.5750\n",
      "Epoch 9/15\n",
      "120/120 [==============================] - 0s 66us/step - loss: 0.9295 - accuracy: 0.5917\n",
      "Epoch 10/15\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.8912 - accuracy: 0.6250\n",
      "Epoch 11/15\n",
      "120/120 [==============================] - 0s 91us/step - loss: 0.8558 - accuracy: 0.6750\n",
      "Epoch 12/15\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.8229 - accuracy: 0.7000\n",
      "Epoch 13/15\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.7926 - accuracy: 0.7250\n",
      "Epoch 14/15\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.7647 - accuracy: 0.7583\n",
      "Epoch 15/15\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.7384 - accuracy: 0.7583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x26d3d65eb00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the neural network.\n",
    "model.fit(inputs_train_white, outputs_train, epochs=15, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['versicolor', 'setosa', 'versicolor', 'versicolor', 'setosa',\n",
       "       'virginica', 'setosa', 'setosa', 'virginica', 'virginica',\n",
       "       'setosa', 'virginica', 'virginica', 'virginica', 'versicolor',\n",
       "       'virginica', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'versicolor', 'virginica', 'versicolor', 'versicolor',\n",
       "       'virginica', 'setosa', 'setosa', 'setosa'], dtype='<U10')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have the network predict the classes of the test inputs.\n",
    "predictions = model.predict(pca.transform(inputs_test)) # Need to whiten training inputs\n",
    "predictions_labels = encoder.inverse_transform(predictions)\n",
    "predictions_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictions_labels == encoder.inverse_transform(outputs_test)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
